{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DK981h_7p0X"
      },
      "source": [
        "Adapted from（参考元）:\n",
        "\n",
        "https://note.com/kohya_ss/n/nee3ed1649fb6\n",
        "\n",
        "https://note.com/kohya_ss/n/n2693183a798e\n",
        "\n",
        "https://github.com/camenduru/stable-diffusion-webui-colab/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "XU7NuMAA2drw"
      },
      "outputs": [],
      "source": [
        "#@title GPU Check（GPUチェック）\n",
        "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "aLWXPZqjsZVV"
      },
      "outputs": [],
      "source": [
        "#@title Installing packages（パッケージのインストール）\n",
        "!pip install -q diffusers[torch]==0.9.0 accelerate transformers==4.21.3 ftfy albumentations opencv-python einops bitsandbytes safetensors pytorch_lightning\n",
        "\n",
        "!pip install -q https://github.com/camenduru/stable-diffusion-webui-colab/releases/download/0.0.15/xformers-0.0.15.dev0+189828c.d20221207-cp38-cp38-linux_x86_64.whl\n",
        "\n",
        "!wget -q https://github.com/thx-pw/stable-diffusion-2-dreambooth/raw/main/model_util.py\n",
        "!wget -q https://github.com/thx-pw/stable-diffusion-2-dreambooth/raw/main/gen_img_diffusers.py\n",
        "!wget -q https://github.com/thx-pw/stable-diffusion-2-dreambooth/raw/main/train_db_fixed.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "RQAwyXYfy6yW"
      },
      "outputs": [],
      "source": [
        "#@title Download SD2 models in size 768, nonema for training（768サイズのSD2モデルをダウンロード、nonemaがトレーニング用）\n",
        "!wget https://huggingface.co/stabilityai/stable-diffusion-2-1/resolve/main/v2-1_768-nonema-pruned.ckpt -P /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "fe-GgtnUVO_e"
      },
      "outputs": [],
      "source": [
        "#@title Uploading of teacher data and automatic generation of regularized images（教師データのアップロードと正則化画像の自動生成）\n",
        "#@markdown Change SKS and CLASS in this cell and run multiple times to learn multiple characters\n",
        "#@markdown > このセルでSKSとCLASSを変更し、複数回実行すると複数キャラの学習が可能\n",
        "\n",
        "#@markdown Tool to resize slow uploads to Colab.：https://www.birme.net/?target_width=768&target_height=768\n",
        "#@markdown > Colabへのアップロードが遅いのでリサイズするツール：https://www.birme.net/?target_width=768&target_height=768\n",
        "SKS = \"zundamon\" #@param {type:\"string\"}\n",
        "CLASS = \"girl\" #@param {type:\"string\"}\n",
        "TRAIN_N_REPEATS = 20 #@param {type:\"integer\"}\n",
        "REG_N_REPEATS = 0 #@param {type:\"integer\"}\n",
        "\n",
        "import os\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "# Location of teacher images（教師データの保存場所）\n",
        "TRAIN_DIR = \"/content/input/train\"\n",
        "!mkdir -p $TRAIN_DIR\n",
        "\n",
        "# Location of regularized images（正則化画像の保存場所）\n",
        "REG_DIR = \"/content/input/reg\"\n",
        "!mkdir -p $REG_DIR\n",
        "\n",
        "# Location of trained models（学習済みモデルの保存場所）\n",
        "OUTPUT_DIR = \"/content/output\" \n",
        "!mkdir -p $OUTPUT_DIR\n",
        "\n",
        "train_path = os.path.join(TRAIN_DIR, f\"{TRAIN_N_REPEATS}_{SKS} {CLASS}\")\n",
        "os.makedirs(train_path, exist_ok=True)\n",
        "reg_path = os.path.join(REG_DIR, f\"{REG_N_REPEATS}_{CLASS}\")\n",
        "os.makedirs(reg_path, exist_ok=True)\n",
        "\n",
        "uploaded = files.upload()\n",
        "for filename in uploaded.keys():\n",
        "    dst_path = os.path.join(train_path, filename)\n",
        "    shutil.move(filename, dst_path)\n",
        "\n",
        "\n",
        "train_num_images = sum(os.path.isfile(os.path.join(train_path, name)) for name in os.listdir(train_path))\n",
        "if REG_N_REPEATS == 0:\n",
        "  reg_num_images = 0\n",
        "elif train_num_images > 0:\n",
        "  reg_num_images = sum(os.path.isfile(os.path.join(reg_path, name)) for name in os.listdir(reg_path))\n",
        "  reg_num_images = (TRAIN_N_REPEATS * train_num_images) // REG_N_REPEATS - reg_num_images\n",
        "  !python gen_img_diffusers.py \\\n",
        "    --ckpt v2-1_768-nonema-pruned.ckpt \\\n",
        "    --outdir {reg_path} \\\n",
        "    --xformers \\\n",
        "    --fp16 \\\n",
        "    --v2 --v_parameterization \\\n",
        "    --W 768 \\\n",
        "    --H 768 \\\n",
        "    --scale 12.5 \\\n",
        "    --sampler ddim \\\n",
        "    --steps 20 \\\n",
        "    --batch_size 4 \\\n",
        "    --images_per_prompt {reg_num_images} \\\n",
        "    --prompt \"{CLASS} --n\"\n",
        "else:\n",
        "  print(\"cancel upload.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjcSXTp-u-Eg"
      },
      "outputs": [],
      "source": [
        "#@title Start learning with DreamBooth（DreamBoothで学習開始）\n",
        "epoch = 10\n",
        "train_batch_size = 1\n",
        "max_train_steps = epoch * (train_num_images * TRAIN_N_REPEATS + reg_num_images * REG_N_REPEATS) // train_batch_size\n",
        "\n",
        "!accelerate launch --num_cpu_threads_per_process 2 train_db_fixed.py \\\n",
        "  --pretrained_model_name_or_path=\"/content/v2-1_768-nonema-pruned.ckpt\" \\\n",
        "  --train_data_dir=$TRAIN_DIR \\\n",
        "  --reg_data_dir=$REG_DIR \\\n",
        "  --output_dir=$OUTPUT_DIR \\\n",
        "  --prior_loss_weight=1.0 \\\n",
        "  --resolution=768 \\\n",
        "  --train_batch_size=$train_batch_size \\\n",
        "  --learning_rate=2e-6 \\\n",
        "  --max_train_steps=$max_train_steps \\\n",
        "  --use_8bit_adam \\\n",
        "  --mixed_precision='fp16' \\\n",
        "  --xformers \\\n",
        "  --cache_latents \\\n",
        "  --gradient_checkpointing \\\n",
        "  --v2 \\\n",
        "  --v_parameterization \\\n",
        "  --save_precision='fp16' \\\n",
        "  --save_every_n_epochs 1 \\\n",
        "  --logging_dir=logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "vH4BWRSlMQOP"
      },
      "outputs": [],
      "source": [
        "#@title Check logs（ログの確認）\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "MYDjfXf8MB2R"
      },
      "outputs": [],
      "source": [
        "#@title Save ckpt to Google Drive（Google Driveにckptを保存）\n",
        "ckpt_name = \"last\" #@param {type:\"string\"}\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "model_checkpoints = \"/content/drive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion\"\n",
        "os.makedirs(model_checkpoints, exist_ok=True)\n",
        "!wget https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/configs/stable-diffusion/v2-inference-v.yaml -O \"{OUTPUT_DIR}/{ckpt_name}.yaml\"\n",
        "!cp \"{OUTPUT_DIR}/{ckpt_name}.ckpt\" {model_checkpoints}\n",
        "!cp \"{OUTPUT_DIR}/{ckpt_name}.yaml\" {model_checkpoints}\n",
        "\n",
        "print(f\"save to {model_checkpoints}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oL6ROH-TcPcJ"
      },
      "outputs": [],
      "source": [
        "#@title Image generation with trained model（学習済みモデルで画像生成）\n",
        "ckpt_name = \"last\" #@param {type:\"string\"}\n",
        "!python gen_img_diffusers.py \\\n",
        "  --ckpt \"{OUTPUT_DIR}/{ckpt_name}.ckpt\" \\\n",
        "  --outdir 'tmp' \\\n",
        "  --xformers \\\n",
        "  --fp16 \\\n",
        "  --v2 --v_parameterization \\\n",
        "  --W 768 \\\n",
        "  --H 768 \\\n",
        "  --scale 12.5 \\\n",
        "  --sampler ddim \\\n",
        "  --steps 20 \\\n",
        "  --batch_size 4 \\\n",
        "  --images_per_prompt 4 \\\n",
        "  --prompt \"{SKS} {CLASS} eating a lunch in MacDonald's --n\"\n",
        "\n",
        "print(\"create to /content/tmp\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.5 ('py')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "bf1b1065d27bb22442f87ae3151ef36acaf1bc99c988efe488d4a234ec420932"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
